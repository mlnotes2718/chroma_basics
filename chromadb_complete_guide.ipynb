{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChromaDB Complete Guide: From Basics to Advanced Use Cases\n",
    "\n",
    "This notebook covers everything you need to know about ChromaDB, including:\n",
    "- Basic setup and operations\n",
    "- File structure understanding\n",
    "- RAG (Retrieval Augmented Generation)\n",
    "- Other practical use cases\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "```bash\n",
    "pip install chromadb\n",
    "pip install openai  # If using OpenAI embeddings\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: ChromaDB Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Simple In-Memory Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents found: [['The dog played in the park', 'Python is a programming language']]\n",
      "Distances: [[1.378471851348877, 1.6124422550201416]]\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "# Create an in-memory client (data disappears when program ends)\n",
    "client = chromadb.Client()\n",
    "\n",
    "# Create a collection (like a table)\n",
    "collection = client.get_or_create_collection(name=\"my_first_collection\")\n",
    "\n",
    "# Add documents\n",
    "collection.add(\n",
    "    documents=[\n",
    "        \"The cat sat on the mat\",\n",
    "        \"The dog played in the park\",\n",
    "        \"Python is a programming language\"\n",
    "    ],\n",
    "    ids=[\"doc1\", \"doc2\", \"doc3\"]\n",
    ")\n",
    "\n",
    "# Query for similar documents\n",
    "results = collection.query(\n",
    "    query_texts=[\"Tell me about animals\"],\n",
    "    n_results=2\n",
    ")\n",
    "\n",
    "print(\"Documents found:\", results['documents'])\n",
    "print(\"Distances:\", results['distances'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: `n_results` will return the top n document with the closest distances, if you do not use the option it will return all. for large document set, `n_results` show be set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Persistent Database (Saves to Disk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data saved to disk!\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "# Create a persistent client (data saved to ./my_chroma_db folder)\n",
    "client = chromadb.PersistentClient(path=\"./data/my_chroma_db\")\n",
    "\n",
    "# Get or create collection\n",
    "collection = client.get_or_create_collection(name=\"persistent_collection\")\n",
    "\n",
    "# Add data\n",
    "collection.add(\n",
    "    documents=[\"This data will persist across sessions\"],\n",
    "    ids=[\"persistent_doc1\"]\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Data saved to disk!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Understanding Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: The cat sat on the mat\n",
      "\n",
      "Embedding (first 10 numbers): [ 0.13040181 -0.01187013 -0.02811698  0.05123861 -0.05597446  0.03019161\n",
      "  0.03016139  0.02469836 -0.01837054  0.05876685]\n",
      "Embedding dimension: 384\n",
      "\n",
      "üí° ChromaDB converted text into a 384-dimensional vector!\n"
     ]
    }
   ],
   "source": [
    "# Let's see what ChromaDB actually stores\n",
    "collection.add(\n",
    "    documents=[\"The cat sat on the mat\"],\n",
    "    ids=[\"doc_with_embedding\"]\n",
    ")\n",
    "\n",
    "# Retrieve the embedding\n",
    "result = collection.get(\n",
    "    ids=[\"doc_with_embedding\"],\n",
    "    include=[\"embeddings\", \"documents\"]\n",
    ")\n",
    "\n",
    "print(\"Original text:\", result['documents'][0])\n",
    "print(\"\\nEmbedding (first 10 numbers):\", result['embeddings'][0][:10])\n",
    "print(\"Embedding dimension:\", len(result['embeddings'][0]))\n",
    "print(\"\\nüí° ChromaDB converted text into a {}-dimensional vector!\".format(len(result['embeddings'][0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: ChromaDB File Structure\n",
    "\n",
    "```\n",
    "./my_chroma_db/\n",
    "‚îú‚îÄ‚îÄ chroma.sqlite3          # Metadata database\n",
    "‚îî‚îÄ‚îÄ <hash-folder>/          # e.g., 4f2a3b1c-...\n",
    "    ‚îú‚îÄ‚îÄ data_level0.bin     # Vector data\n",
    "    ‚îú‚îÄ‚îÄ header.bin          # Index metadata\n",
    "    ‚îú‚îÄ‚îÄ length.bin          # Document lengths\n",
    "    ‚îî‚îÄ‚îÄ link_lists.bin      # Graph connections (for HNSW)\n",
    "```\n",
    "\n",
    "### What Each Component Does:\n",
    "\n",
    "#### 1. `chroma.sqlite3` - The Metadata Store\n",
    "- Collection names and settings\n",
    "- Document IDs\n",
    "- Document text (actual strings)\n",
    "- Metadata\n",
    "- Configuration (embedding function, distance metric)\n",
    "\n",
    "**Think of it as:** The catalog/index system\n",
    "\n",
    "#### 2. Hash Folder - The Vector Store\n",
    "- **`data_level0.bin`**: Actual embedding vectors\n",
    "- **`header.bin`**: Index structure metadata\n",
    "- **`length.bin`**: Vector dimensions info\n",
    "- **`link_lists.bin`**: HNSW graph for fast search\n",
    "\n",
    "**Think of it as:** The warehouse for numerical data\n",
    "\n",
    "### Key Concepts Summary:\n",
    "\n",
    "| What | Where Stored | When Created |\n",
    "|------|--------------|-------------|\n",
    "| **Document text** | `chroma.sqlite3` | When you `.add()` |\n",
    "| **Document vectors** | `data_level0.bin` | When you `.add()` (via embedding function) |\n",
    "| **Query vector** | Nowhere (temporary) | When you `.query()` (on-the-fly) |\n",
    "| **Distance** | Nowhere | When you `.query()` (calculated on-the-fly) |\n",
    "\n",
    "‚úÖ Distance is calculated **on-the-fly** during search  \n",
    "‚úÖ If a document is never queried, no distance is calculated  \n",
    "‚úÖ Distance only exists **between two vectors** (query ‚Üî document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Using Different Embedding Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Default Embedding (sentence-transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default embedding model: all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "# Default uses 'all-MiniLM-L6-v2' sentence transformer\n",
    "client = chromadb.Client()\n",
    "collection = client.create_collection(name=\"default_embeddings\")\n",
    "\n",
    "collection.add(\n",
    "    documents=[\"Default embedding model\"],\n",
    "    ids=[\"default1\"]\n",
    ")\n",
    "\n",
    "print(\"Using default embedding model: all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 OpenAI Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with OpenAI embeddings: [['The dog played in the park', 'The dog played in the park']]\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Set your OpenAI API key\n",
    "load_dotenv()\n",
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY environment variable is not set\")\n",
    "\n",
    "# Create OpenAI embedding function\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "    api_key=openai_api_key,\n",
    "    model_name=\"text-embedding-3-small\"  # 1536 dimensions\n",
    ")\n",
    "\n",
    "# Create collection with OpenAI embeddings\n",
    "client = chromadb.PersistentClient(path=\"./data/openai_chroma_db\")\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"openai_collection\",\n",
    "    embedding_function=openai_ef\n",
    ")\n",
    "\n",
    "collection.add(\n",
    "    documents=[\n",
    "        \"The cat sat on the mat\",\n",
    "        \"The dog played in the park\"\n",
    "    ],\n",
    "    ids=[\"openai_doc1\", \"openai_doc2\"]\n",
    ")\n",
    "\n",
    "results = collection.query(\n",
    "    query_texts=[\"Tell me about animals\"],\n",
    "    n_results=2\n",
    ")\n",
    "\n",
    "print(\"Results with OpenAI embeddings:\", results['documents'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Custom Embedding Function (Advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using custom embedding function!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/sxtf7fld3sjcy7p8b52tckwc0000gs/T/ipykernel_6208/3863964273.py:15: DeprecationWarning: The class MyCustomEmbeddingFunction does not implement __init__. This will be required in a future version.\n",
      "  custom_ef = MyCustomEmbeddingFunction()\n"
     ]
    }
   ],
   "source": [
    "from chromadb.api.types import Documents, EmbeddingFunction, Embeddings\n",
    "import numpy as np\n",
    "\n",
    "class MyCustomEmbeddingFunction(EmbeddingFunction):\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        # This is a dummy example - replace with your actual embedding logic\n",
    "        embeddings = []\n",
    "        for doc in input:\n",
    "            # Example: create a random 128-dim vector (replace with real embeddings)\n",
    "            embedding = np.random.rand(128).tolist()\n",
    "            embeddings.append(embedding)\n",
    "        return embeddings\n",
    "\n",
    "# Use custom embedding function\n",
    "custom_ef = MyCustomEmbeddingFunction()\n",
    "collection = client.create_collection(\n",
    "    name=\"custom_embeddings\",\n",
    "    embedding_function=custom_ef\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Using custom embedding function!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: RAG (Retrieval Augmented Generation)\n",
    "\n",
    "### What is RAG?\n",
    "\n",
    "RAG combines ChromaDB (retrieval) with LLMs (generation) to answer questions using your custom data.\n",
    "\n",
    "**The Flow:**\n",
    "```\n",
    "User Question \n",
    "    ‚Üì\n",
    "1. Convert question to embedding\n",
    "    ‚Üì\n",
    "2. Search ChromaDB for similar documents\n",
    "    ‚Üì\n",
    "3. Retrieve top relevant documents\n",
    "    ‚Üì\n",
    "4. Give LLM: [Question + Retrieved Documents]\n",
    "    ‚Üì\n",
    "5. LLM generates answer based on context\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 RAG Example: Company Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Company knowledge base loaded!\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "# Setup ChromaDB with company documents\n",
    "client = chromadb.PersistentClient(path=\"./data/rag_example_db\")\n",
    "collection = client.get_or_create_collection(name=\"company_docs\")\n",
    "\n",
    "# Add company documents\n",
    "company_docs = [\n",
    "    \"Q3 2024 Revenue Report: Total revenue was $5.2M, up 15% from Q2. Major growth in enterprise segment.\",\n",
    "    \"Vacation Policy: Employees get 15 days paid vacation per year. Must be requested 2 weeks in advance.\",\n",
    "    \"Remote Work Policy: Employees can work remotely up to 3 days per week. Must coordinate with team.\",\n",
    "    \"Health Benefits: Company covers 80% of health insurance premiums. Dental and vision included.\"\n",
    "]\n",
    "\n",
    "collection.add(\n",
    "    documents=company_docs,\n",
    "    ids=[f\"doc_{i}\" for i in range(len(company_docs))]\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Company knowledge base loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What was our Q3 revenue?\n",
      "\n",
      "Retrieved Documents:\n",
      "  1. Q3 2024 Revenue Report: Total revenue was $5.2M, up 15% from Q2. Major growth in enterprise segment....\n",
      "  2. Health Benefits: Company covers 80% of health insurance premiums. Dental and vision included....\n",
      "  3. Vacation Policy: Employees get 15 days paid vacation per year. Must be requested 2 weeks in advance....\n",
      "\n",
      "Prompt to send to LLM:\n",
      "Based on the following information:\n",
      "\n",
      "Q3 2024 Revenue Report: Total revenue was $5.2M, up 15% from Q2. Major growth in enterprise segment.\n",
      "\n",
      "Health Benefits: Company covers 80% of health insurance premiums. Dental and vision included.\n",
      "\n",
      "Vacation Policy: Employees get 15 days paid vacation per year. Must be requested 2 weeks in advance.\n",
      "\n",
      "Answer this question: What was our Q3 revenue?\n",
      "\n",
      "If the information doesn't contain the answer, say so.\n"
     ]
    }
   ],
   "source": [
    "# RAG Function\n",
    "def rag_query(question, collection, n_results=3):\n",
    "    \"\"\"\n",
    "    Retrieval Augmented Generation query\n",
    "    \"\"\"\n",
    "    # Step 1: Search ChromaDB for relevant context\n",
    "    results = collection.query(\n",
    "        query_texts=[question],\n",
    "        n_results=n_results\n",
    "    )\n",
    "    \n",
    "    # Step 2: Get retrieved documents\n",
    "    retrieved_docs = results['documents'][0]\n",
    "    context = \"\\n\\n\".join(retrieved_docs)\n",
    "    \n",
    "    # Step 3: Build prompt for LLM\n",
    "    prompt = f\"\"\"Based on the following information:\n",
    "\n",
    "{context}\n",
    "\n",
    "Answer this question: {question}\n",
    "\n",
    "If the information doesn't contain the answer, say so.\"\"\"\n",
    "    \n",
    "    return {\n",
    "        'prompt': prompt,\n",
    "        'retrieved_docs': retrieved_docs,\n",
    "        'distances': results['distances'][0]\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "question = \"What was our Q3 revenue?\"\n",
    "result = rag_query(question, collection)\n",
    "\n",
    "print(\"Question:\", question)\n",
    "print(\"\\nRetrieved Documents:\")\n",
    "for i, doc in enumerate(result['retrieved_docs']):\n",
    "    print(f\"  {i+1}. {doc[:100]}...\")\n",
    "print(\"\\nPrompt to send to LLM:\")\n",
    "print(result['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùì Question: How many vacation days do I get?\n",
      "üìÑ Retrieved: Vacation Policy: Employees get 15 days paid vacation per year. Must be requested 2 weeks in advance....\n",
      "üìä Distance: 0.5961\n",
      "\n",
      "‚ùì Question: Can I work from home?\n",
      "üìÑ Retrieved: Remote Work Policy: Employees can work remotely up to 3 days per week. Must coordinate with team....\n",
      "üìä Distance: 1.2501\n",
      "\n",
      "‚ùì Question: What are the health benefits?\n",
      "üìÑ Retrieved: Health Benefits: Company covers 80% of health insurance premiums. Dental and vision included....\n",
      "üìä Distance: 0.9587\n",
      "\n",
      "‚ùì Question: What's our office address?\n",
      "üìÑ Retrieved: Remote Work Policy: Employees can work remotely up to 3 days per week. Must coordinate with team....\n",
      "üìä Distance: 1.7489\n"
     ]
    }
   ],
   "source": [
    "# Try different questions\n",
    "questions = [\n",
    "    \"How many vacation days do I get?\",\n",
    "    \"Can I work from home?\",\n",
    "    \"What are the health benefits?\",\n",
    "    \"What's our office address?\"  # This is NOT in the database\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    result = rag_query(q, collection, n_results=1)\n",
    "    print(f\"\\n‚ùì Question: {q}\")\n",
    "    print(f\"üìÑ Retrieved: {result['retrieved_docs'][0][:100]}...\")\n",
    "    print(f\"üìä Distance: {result['distances'][0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Other Use Cases (Beyond RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Semantic Search (No LLM Needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Search: 'cord for phone'\n",
      "‚úÖ Found: USB-C charging cable 6ft braided nylon, fast charging\n",
      "\n",
      "üîç Search: 'something for music'\n",
      "‚úÖ Found: Wireless Bluetooth headphones with noise cancellation, 30-hour battery\n",
      "\n",
      "üîç Search: 'typing device'\n",
      "‚úÖ Found: Mechanical keyboard RGB backlit gaming switches\n"
     ]
    }
   ],
   "source": [
    "# E-commerce product search\n",
    "client = chromadb.Client()\n",
    "products = client.get_or_create_collection(name=\"products\")\n",
    "\n",
    "products.add(\n",
    "    documents=[\n",
    "        \"Wireless Bluetooth headphones with noise cancellation, 30-hour battery\",\n",
    "        \"USB-C charging cable 6ft braided nylon, fast charging\",\n",
    "        \"Laptop stand adjustable aluminum ergonomic design\",\n",
    "        \"Mechanical keyboard RGB backlit gaming switches\"\n",
    "    ],\n",
    "    ids=[\"prod1\", \"prod2\", \"prod3\", \"prod4\"]\n",
    ")\n",
    "\n",
    "# User searches with natural language\n",
    "search_queries = [\n",
    "    \"cord for phone\",  # Finds charging cable\n",
    "    \"something for music\",  # Finds headphones\n",
    "    \"typing device\"  # Finds keyboard\n",
    "]\n",
    "\n",
    "for query in search_queries:\n",
    "    results = products.query(query_texts=[query], n_results=1)\n",
    "    print(f\"\\nüîç Search: '{query}'\")\n",
    "    print(f\"‚úÖ Found: {results['documents'][0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé¨ Because you watched: 'Space Adventure'\n",
      "\n",
      "You might also like:\n",
      "  1. Action-packed superhero movie with epic fight scenes\n",
      "  2. Sci-fi thriller about AI taking over the world\n"
     ]
    }
   ],
   "source": [
    "# Movie recommendation\n",
    "movies = client.get_or_create_collection(name=\"movies\")\n",
    "\n",
    "movies.add(\n",
    "    documents=[\n",
    "        \"A thrilling space adventure with aliens and cosmic battles\",\n",
    "        \"Romantic comedy set in Paris with a charming love story\",\n",
    "        \"Sci-fi thriller about AI taking over the world\",\n",
    "        \"Action-packed superhero movie with epic fight scenes\",\n",
    "        \"Heartwarming drama about family and redemption\"\n",
    "    ],\n",
    "    ids=[\"movie1\", \"movie2\", \"movie3\", \"movie4\", \"movie5\"]\n",
    ")\n",
    "\n",
    "# User watched: \"A thrilling space adventure with aliens and cosmic battles\"\n",
    "# Find similar movies\n",
    "user_watched = \"A thrilling space adventure with aliens and cosmic battles\"\n",
    "recommendations = movies.query(query_texts=[user_watched], n_results=3)\n",
    "\n",
    "print(\"üé¨ Because you watched: 'Space Adventure'\")\n",
    "print(\"\\nYou might also like:\")\n",
    "for i, movie in enumerate(recommendations['documents'][0][1:], 1):  # Skip first (itself)\n",
    "    print(f\"  {i}. {movie}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Duplicate Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New ticket: 'Unable to log into the application'\n",
      "\n",
      "Most similar existing ticket: 'App crashes when I try to login'\n",
      "Distance: 0.5349\n",
      "\n",
      "‚úÖ New unique ticket\n"
     ]
    }
   ],
   "source": [
    "# Customer support ticket deduplication\n",
    "tickets = client.get_or_create_collection(name=\"support_tickets\")\n",
    "\n",
    "tickets.add(\n",
    "    documents=[\n",
    "        \"App crashes when I try to login\",\n",
    "        \"Cannot sign in, app freezes\",\n",
    "        \"Login button not working\"\n",
    "    ],\n",
    "    ids=[\"ticket1\", \"ticket2\", \"ticket3\"]\n",
    ")\n",
    "\n",
    "# New ticket comes in\n",
    "new_ticket = \"Unable to log into the application\"\n",
    "\n",
    "# Check for duplicates\n",
    "results = tickets.query(query_texts=[new_ticket], n_results=1)\n",
    "distance = results['distances'][0][0]\n",
    "\n",
    "print(f\"New ticket: '{new_ticket}'\")\n",
    "print(f\"\\nMost similar existing ticket: '{results['documents'][0][0]}'\")\n",
    "print(f\"Distance: {distance:.4f}\")\n",
    "\n",
    "if distance < 0.5:  # Threshold for \"too similar\"\n",
    "    print(\"\\n‚ö†Ô∏è Possible duplicate detected!\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ New unique ticket\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Content Categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Feedback: 'App crashes when I try to login'\n",
      "üè∑Ô∏è  Category: Login Issues\n",
      "\n",
      "üìù Feedback: 'Cannot sign in, keeps failing'\n",
      "üè∑Ô∏è  Category: Login Issues\n",
      "\n",
      "üìù Feedback: 'Love the new dark mode feature'\n",
      "üè∑Ô∏è  Category: UI Feedback\n",
      "\n",
      "üìù Feedback: 'Great UI updates in latest version'\n",
      "üè∑Ô∏è  Category: UI Feedback\n",
      "\n",
      "üìù Feedback: 'Checkout process is broken'\n",
      "üè∑Ô∏è  Category: Payment Problems\n",
      "\n",
      "üìù Feedback: 'Payment doesn't work'\n",
      "üè∑Ô∏è  Category: Payment Problems\n"
     ]
    }
   ],
   "source": [
    "# Categorize customer feedback\n",
    "feedback = client.get_or_create_collection(name=\"feedback\")\n",
    "\n",
    "feedback.add(\n",
    "    documents=[\n",
    "        \"App crashes when I try to login\",\n",
    "        \"Cannot sign in, keeps failing\",\n",
    "        \"Love the new dark mode feature\",\n",
    "        \"Great UI updates in latest version\",\n",
    "        \"Checkout process is broken\",\n",
    "        \"Payment doesn't work\"\n",
    "    ],\n",
    "    ids=[\"f1\", \"f2\", \"f3\", \"f4\", \"f5\", \"f6\"]\n",
    ")\n",
    "\n",
    "# Define categories\n",
    "categories = {\n",
    "    \"Login Issues\": \"problems with authentication and signing in\",\n",
    "    \"UI Feedback\": \"comments about design and user interface\",\n",
    "    \"Payment Problems\": \"issues with checkout and payment processing\"\n",
    "}\n",
    "\n",
    "# Categorize each feedback\n",
    "all_feedback = feedback.get()\n",
    "\n",
    "for doc_id, doc in zip(all_feedback['ids'], all_feedback['documents']):\n",
    "    print(f\"\\nüìù Feedback: '{doc}'\")\n",
    "    \n",
    "    # Find best matching category\n",
    "    best_category = None\n",
    "    best_distance = float('inf')\n",
    "    \n",
    "    for category_name, category_desc in categories.items():\n",
    "        result = feedback.query(query_texts=[category_desc], n_results=10)\n",
    "        if doc_id in result['ids'][0]:\n",
    "            idx = result['ids'][0].index(doc_id)\n",
    "            distance = result['distances'][0][idx]\n",
    "            if distance < best_distance:\n",
    "                best_distance = distance\n",
    "                best_category = category_name\n",
    "    \n",
    "    print(f\"üè∑Ô∏è  Category: {best_category}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 AI Agent Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User asks: 'recommend a good restaurant for dinner'\n",
      "\n",
      "üß† Agent remembers:\n",
      "  - User prefers vegetarian restaurants\n",
      "  - User's favorite cuisine is Italian\n",
      "  - User lives in San Francisco\n",
      "\n",
      "üí° Agent can now give personalized recommendations!\n"
     ]
    }
   ],
   "source": [
    "# Give AI agent long-term memory\n",
    "agent_memory = client.get_or_create_collection(name=\"agent_memory\")\n",
    "\n",
    "# Store user preferences and past interactions\n",
    "agent_memory.add(\n",
    "    documents=[\n",
    "        \"User prefers vegetarian restaurants\",\n",
    "        \"User's favorite cuisine is Italian\",\n",
    "        \"User is allergic to peanuts\",\n",
    "        \"User lives in San Francisco\"\n",
    "    ],\n",
    "    ids=[\"pref1\", \"pref2\", \"pref3\", \"pref4\"]\n",
    ")\n",
    "\n",
    "# Later, when user asks for recommendations\n",
    "user_query = \"recommend a good restaurant for dinner\"\n",
    "\n",
    "# Retrieve relevant memories\n",
    "relevant_memories = agent_memory.query(\n",
    "    query_texts=[user_query],\n",
    "    n_results=3\n",
    ")\n",
    "\n",
    "print(f\"User asks: '{user_query}'\")\n",
    "print(\"\\nüß† Agent remembers:\")\n",
    "for memory in relevant_memories['documents'][0]:\n",
    "    print(f\"  - {memory}\")\n",
    "print(\"\\nüí° Agent can now give personalized recommendations!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Advanced Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Using Metadata for Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python documents only:\n",
      "  - Python tutorial for beginners - Updated 2024\n",
      "  - Advanced Python patterns\n"
     ]
    }
   ],
   "source": [
    "# Add documents with metadata\n",
    "advanced_collection = client.get_or_create_collection(name=\"advanced_features\")\n",
    "\n",
    "advanced_collection.add(\n",
    "    documents=[\n",
    "        \"Python tutorial for beginners\",\n",
    "        \"Advanced Python patterns\",\n",
    "        \"JavaScript basics guide\",\n",
    "        \"React framework tutorial\"\n",
    "    ],\n",
    "    metadatas=[\n",
    "        {\"language\": \"python\", \"level\": \"beginner\"},\n",
    "        {\"language\": \"python\", \"level\": \"advanced\"},\n",
    "        {\"language\": \"javascript\", \"level\": \"beginner\"},\n",
    "        {\"language\": \"javascript\", \"level\": \"intermediate\"}\n",
    "    ],\n",
    "    ids=[\"doc1\", \"doc2\", \"doc3\", \"doc4\"]\n",
    ")\n",
    "\n",
    "# Query with metadata filter\n",
    "results = advanced_collection.query(\n",
    "    query_texts=[\"learning programming\"],\n",
    "    n_results=5,\n",
    "    where={\"language\": \"python\"}  # Only Python documents\n",
    ")\n",
    "\n",
    "print(\"Python documents only:\")\n",
    "for doc in results['documents'][0]:\n",
    "    print(f\"  - {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Updating and Deleting Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining documents:\n",
      "  doc1: Python tutorial for beginners - Updated 2024\n",
      "  doc2: Advanced Python patterns\n",
      "  doc3: JavaScript basics guide\n"
     ]
    }
   ],
   "source": [
    "# Update a document\n",
    "advanced_collection.update(\n",
    "    ids=[\"doc1\"],\n",
    "    documents=[\"Python tutorial for beginners - Updated 2024\"]\n",
    ")\n",
    "\n",
    "# Delete a document\n",
    "advanced_collection.delete(ids=[\"doc4\"])\n",
    "\n",
    "# Verify changes\n",
    "all_docs = advanced_collection.get()\n",
    "print(\"Remaining documents:\")\n",
    "for doc_id, doc in zip(all_docs['ids'], all_docs['documents']):\n",
    "    print(f\"  {doc_id}: {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Collection Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All collections:\n",
      "  - my_first_collection\n",
      "  - default_embeddings\n",
      "  - advanced_features\n",
      "  - movies\n",
      "  - support_tickets\n",
      "  - feedback\n",
      "  - products\n",
      "  - agent_memory\n",
      "\n",
      "Documents in 'advanced_features': 3\n"
     ]
    }
   ],
   "source": [
    "# List all collections\n",
    "collections = client.list_collections()\n",
    "print(\"All collections:\")\n",
    "for col in collections:\n",
    "    print(f\"  - {col.name}\")\n",
    "\n",
    "# Get collection info\n",
    "collection_info = advanced_collection.count()\n",
    "print(f\"\\nDocuments in 'advanced_features': {collection_info}\")\n",
    "\n",
    "# Delete a collection (careful!)\n",
    "# client.delete_collection(name=\"collection_to_delete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary: When to Use ChromaDB\n",
    "\n",
    "### ‚úÖ Use ChromaDB when you need:\n",
    "\n",
    "1. **RAG (Retrieval Augmented Generation)**\n",
    "   - Give LLMs access to your custom data\n",
    "   - Build chatbots with company knowledge\n",
    "   - Document Q&A systems\n",
    "\n",
    "2. **Semantic Search**\n",
    "   - E-commerce product search\n",
    "   - Document/knowledge base search\n",
    "   - Finding similar content\n",
    "\n",
    "3. **Recommendations**\n",
    "   - \"Customers also liked...\"\n",
    "   - Content recommendations\n",
    "   - Similar items/products\n",
    "\n",
    "4. **Duplicate Detection**\n",
    "   - Find similar tickets/issues\n",
    "   - Prevent duplicate content\n",
    "   - Plagiarism detection\n",
    "\n",
    "5. **Categorization**\n",
    "   - Auto-categorize feedback\n",
    "   - Organize documents by topic\n",
    "   - Route support tickets\n",
    "\n",
    "6. **AI Agent Memory**\n",
    "   - Long-term memory for chatbots\n",
    "   - Personalized AI assistants\n",
    "   - Context-aware responses\n",
    "\n",
    "### üîë Key Concepts:\n",
    "\n",
    "- **Embeddings** encode meaning as numerical vectors\n",
    "- **Distance** measures similarity between vectors\n",
    "- Similar meanings ‚Üí close vectors (small distance)\n",
    "- ChromaDB handles embedding generation automatically\n",
    "- You can use custom embedding models\n",
    "\n",
    "### üìÅ Remember:\n",
    "\n",
    "- Use `Client()` for temporary/testing\n",
    "- Use `PersistentClient()` for production\n",
    "- Data stored in SQLite (metadata) + bin files (vectors)\n",
    "- Distance calculated on-the-fly during search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Try building a RAG application** with your own documents\n",
    "2. **Experiment with different embedding models** (OpenAI, sentence-transformers, custom)\n",
    "3. **Explore metadata filtering** for more precise searches\n",
    "4. **Integrate with LLM APIs** (OpenAI, Anthropic Claude, local models)\n",
    "5. **Scale up** with larger document collections\n",
    "\n",
    "### Useful Resources:\n",
    "- [ChromaDB Documentation](https://docs.trychroma.com/)\n",
    "- [Sentence Transformers](https://www.sbert.net/)\n",
    "- [OpenAI Embeddings](https://platform.openai.com/docs/guides/embeddings)\n",
    "\n",
    "Happy coding! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chromadb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
