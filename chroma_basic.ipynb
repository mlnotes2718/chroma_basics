{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cccbbfa1",
   "metadata": {},
   "source": [
    "# ChromaDB Basic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da08237f",
   "metadata": {},
   "source": [
    "- https://www.perplexity.ai/search/in-vector-database-chroma-is-e-fT1gti.vRrSmTl1BWAZtyQ#0\n",
    "- https://cookbook.chromadb.dev/core/api/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e83879f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing results\n",
      "{'ids': [['doc2', 'doc3']], 'embeddings': None, 'documents': [['The dog played in the park', 'Python is a programming language']], 'uris': None, 'included': ['metadatas', 'documents', 'distances'], 'data': None, 'metadatas': [[None, None]], 'distances': [[1.378471851348877, 1.6124422550201416]]}\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "# Create a client (this is your database connection)\n",
    "client = chromadb.Client()\n",
    "\n",
    "# Create a collection (think of it like a table)\n",
    "collection = client.create_collection(name=\"my_first_collection\")\n",
    "\n",
    "\n",
    "# Add some documents\n",
    "collection.add(\n",
    "    documents=[\n",
    "        \"The cat sat on the mat\",\n",
    "        \"The dog played in the park\",\n",
    "        \"Python is a programming language\"\n",
    "    ],\n",
    "    ids=[\"doc1\", \"doc2\", \"doc3\"]\n",
    ")\n",
    "\n",
    "# Search for similar documents\n",
    "results = collection.query(\n",
    "    query_texts=[\"Tell me about animals\"],\n",
    "    n_results=2\n",
    ")\n",
    "\n",
    "print('Showing results')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2abad774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: ['The cat sat on the mat']\n",
      "\n",
      "Embedding (first 10 numbers): [ 0.13040181 -0.01187013 -0.02811698  0.05123861 -0.05597446  0.03019161\n",
      "  0.03016139  0.02469836 -0.01837054  0.05876685]\n",
      "Embedding length: 384\n"
     ]
    }
   ],
   "source": [
    "client = chromadb.Client()\n",
    "collection = client.create_collection(name=\"test_embeddings\")\n",
    "\n",
    "# Add documents\n",
    "collection.add(\n",
    "    documents=[\"The cat sat on the mat\"],\n",
    "    ids=[\"doc1\"]\n",
    ")\n",
    "\n",
    "# Let's peek at what ChromaDB actually stored\n",
    "results = collection.get(\n",
    "    ids=[\"doc1\"],\n",
    "    include=[\"embeddings\", \"documents\"]\n",
    ")\n",
    "\n",
    "print(\"Document:\", results['documents'])\n",
    "print(\"\\nEmbedding (first 10 numbers):\", results['embeddings'][0][:10])\n",
    "print(\"Embedding length:\", len(results['embeddings'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb43de17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to /data/my_chroma_db folder\n"
     ]
    }
   ],
   "source": [
    "import chromadb.api\n",
    "\n",
    "chromadb.api.client.SharedSystemClient.clear_system_cache()\n",
    "\n",
    "import chromadb\n",
    "\n",
    "# This creates a local database folder\n",
    "client = chromadb.PersistentClient(path=\"./data/my_chroma_db\")\n",
    "\n",
    "collection = client.get_or_create_collection(name=\"persistent_collection\")\n",
    "\n",
    "collection.add(\n",
    "    documents=[\"This will be saved to disk\"],\n",
    "    ids=[\"doc1\"]\n",
    ")\n",
    "\n",
    "print(\"Data saved to /data/my_chroma_db folder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3e5e43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing results\n",
      "{'ids': [['doc1']], 'embeddings': None, 'documents': [['This will be saved to disk']], 'uris': None, 'included': ['metadatas', 'documents', 'distances'], 'data': None, 'metadatas': [[None]], 'distances': [[1.9052947759628296]]}\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "# This creates a local database folder\n",
    "client = chromadb.PersistentClient(path=\"./data/my_chroma_db\")\n",
    "\n",
    "collection = client.get_or_create_collection(name=\"persistent_collection\")\n",
    "\n",
    "# Search for similar documents\n",
    "results = collection.query(\n",
    "    query_texts=[\"Tell me about animals\"],\n",
    "    n_results=2\n",
    ")\n",
    "\n",
    "print('Showing results')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a403efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents in collection: ['This will be saved to disk']\n",
      "Number of documents: 1\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "client = chromadb.PersistentClient(path=\"./data/my_chroma_db\")\n",
    "collection = client.get_or_create_collection(name=\"persistent_collection\")\n",
    "\n",
    "# Let's see what's actually IN the collection\n",
    "all_docs = collection.get()\n",
    "print(\"Documents in collection:\", all_docs['documents'])\n",
    "print(\"Number of documents:\", len(all_docs['documents']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6c94e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Query: 'Tell me about animals' ---\n",
      "1. Distance: 1.3785 - 'The dog played in the park'\n",
      "2. Distance: 1.6124 - 'Python is a programming language'\n",
      "3. Distance: 1.8603 - 'The cat sat on the mat'\n",
      "\n",
      "--- Query: 'cat' ---\n",
      "1. Distance: 0.9752 - 'The cat sat on the mat'\n",
      "2. Distance: 1.5271 - 'Python is a programming language'\n",
      "3. Distance: 1.6214 - 'The dog played in the park'\n",
      "\n",
      "--- Query: 'pets and animals' ---\n",
      "1. Distance: 1.1869 - 'The dog played in the park'\n",
      "2. Distance: 1.5547 - 'The cat sat on the mat'\n",
      "3. Distance: 1.6321 - 'Python is a programming language'\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "client = chromadb.Client()\n",
    "collection = client.create_collection(name=\"animal_test\")\n",
    "\n",
    "collection.add(\n",
    "    documents=[\n",
    "        \"The cat sat on the mat\",\n",
    "        \"The dog played in the park\",\n",
    "        \"Python is a programming language\"\n",
    "    ],\n",
    "    ids=[\"doc1\", \"doc2\", \"doc3\"]\n",
    ")\n",
    "\n",
    "# Let's try different queries\n",
    "queries = [\n",
    "    \"Tell me about animals\",\n",
    "    \"cat\",\n",
    "    \"pets and animals\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    results = collection.query(query_texts=[query], n_results=3)\n",
    "    print(f\"\\n--- Query: '{query}' ---\")\n",
    "    for i, (doc, distance) in enumerate(zip(results['documents'][0], results['distances'][0])):\n",
    "        print(f\"{i+1}. Distance: {distance:.4f} - '{doc}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc569e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Query: 'animal' ---\n",
      "  0.0000 - 'animal'\n",
      "  0.3688 - 'dog'\n",
      "  0.6511 - 'cat'\n",
      "  0.7057 - 'Tell me about animals'\n",
      "  1.5166 - 'The cat sat on the mat'\n",
      "\n",
      "--- Query: 'animals' ---\n",
      "  0.3075 - 'animal'\n",
      "  0.4693 - 'Tell me about animals'\n",
      "  0.7699 - 'dog'\n",
      "  0.9449 - 'cat'\n",
      "  1.6997 - 'The cat sat on the mat'\n",
      "\n",
      "--- Query: 'cat' ---\n",
      "  0.0000 - 'cat'\n",
      "  0.6511 - 'animal'\n",
      "  0.6787 - 'dog'\n",
      "  0.9752 - 'The cat sat on the mat'\n",
      "  1.3497 - 'Tell me about animals'\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "client = chromadb.Client()\n",
    "collection = client.create_collection(name=\"word_test\")\n",
    "\n",
    "# Let's test single words vs. sentences\n",
    "collection.add(\n",
    "    documents=[\n",
    "        \"cat\",\n",
    "        \"dog\", \n",
    "        \"animal\",\n",
    "        \"The cat sat on the mat\",\n",
    "        \"Tell me about animals\"\n",
    "    ],\n",
    "    ids=[\"word_cat\", \"word_dog\", \"word_animal\", \"sentence_cat\", \"question_animals\"]\n",
    ")\n",
    "\n",
    "# Compare these queries\n",
    "test_queries = [\"animal\", \"animals\", \"cat\"]\n",
    "\n",
    "for query in test_queries:\n",
    "    results = collection.query(query_texts=[query], n_results=5)\n",
    "    print(f\"\\n--- Query: '{query}' ---\")\n",
    "    for doc, dist in zip(results['documents'][0], results['distances'][0]):\n",
    "        print(f\"  {dist:.4f} - '{doc}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd807c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from huggingface_hub import login # Or other HF libraries\n",
    "\n",
    "load_dotenv() # Loads variables from .env\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59f86cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Now use the token with HF libraries, e.g.:\n",
    "login(token=hf_token)\n",
    "# Or directly in from_pretrained:\n",
    "# model = AutoModel.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", token=hf_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "468273cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.2.2\n"
     ]
    }
   ],
   "source": [
    "import sentence_transformers\n",
    "print(sentence_transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31770c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ffa501d14141d1ad024faeeac4844d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: sentence-transformers/paraphrase-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "# Example: Using OpenAI embeddings (you'll replace this with your own)\n",
    "# openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "#     api_key=\"your-api-key\",\n",
    "#     model_name=\"text-embedding-ada-002\"\n",
    "# )\n",
    "\n",
    "# Or using SentenceTransformers with a different model\n",
    "sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "    model_name=\"paraphrase-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "client = chromadb.Client()\n",
    "collection = client.create_collection(\n",
    "    name=\"custom_embeddings\",\n",
    "    embedding_function=sentence_transformer_ef\n",
    ")\n",
    "\n",
    "collection.add(\n",
    "    documents=[\"The cat sat on the mat\"],\n",
    "    ids=[\"doc1\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdb51fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c15297ed2c42c181e9ffb549a1953b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel LOAD REPORT from: gpt2\n",
      "Key                  | Status     |  | \n",
      "---------------------+------------+--+-\n",
      "h.{0...11}.attn.bias | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens (IDs): [464, 3797, 3332, 319, 262, 2603]\n",
      "Tokens (text): ['The', ' cat', ' sat', ' on', ' the', ' mat']\n",
      "\n",
      "What's inside the model:\n",
      "- Number of hidden layers: 13\n",
      "- Shape of last hidden state: torch.Size([1, 6, 768])\n",
      "- That means: [batch_size, sequence_length, embedding_dimension]\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "\n",
    "model_name = 'gpt2'\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "text = \"The cat sat on the mat\"\n",
    "\n",
    "# Step 1: Tokenization\n",
    "tokens = tokenizer.encode(text)\n",
    "print(\"Tokens (IDs):\", tokens)\n",
    "print(\"Tokens (text):\", [tokenizer.decode([t]) for t in tokens])\n",
    "\n",
    "# Step 2: What happens inside the model?\n",
    "input_ids = torch.tensor([tokens])\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids, output_hidden_states=True)\n",
    "\n",
    "print(\"\\nWhat's inside the model:\")\n",
    "print(\"- Number of hidden layers:\", len(outputs.hidden_states))\n",
    "print(\"- Shape of last hidden state:\", outputs.hidden_states[-1].shape)\n",
    "print(\"- That means: [batch_size, sequence_length, embedding_dimension]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e44e61a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: [['The dog played in the park', 'The cat sat on the mat', 'Python is a programming language']]\n",
      "Distances: [[0.7549846768379211, 0.7731590270996094, 0.8642709255218506]]\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "import os\n",
    "\n",
    "load_dotenv() # Loads variables from .env\n",
    "openai_token = os.getenv(\"OPENAI_TOKEN\")\n",
    "\n",
    "# Set your API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_token  # Replace with your actual key\n",
    "\n",
    "# Create OpenAI embedding function\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    model_name=\"text-embedding-3-small\"  # or \"text-embedding-3-large\"\n",
    ")\n",
    "\n",
    "# Create persistent client with OpenAI embeddings\n",
    "client = chromadb.PersistentClient(path=\"./data/openai_chroma_db\")\n",
    "\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"openai_collection\",\n",
    "    embedding_function=openai_ef\n",
    ")\n",
    "\n",
    "# Add documents\n",
    "collection.add(\n",
    "    documents=[\n",
    "        \"The cat sat on the mat\",\n",
    "        \"The dog played in the park\",\n",
    "        \"Python is a programming language\"\n",
    "    ],\n",
    "    ids=[\"doc1\", \"doc2\", \"doc3\"]\n",
    ")\n",
    "\n",
    "# Query\n",
    "results = collection.query(\n",
    "    query_texts=[\"Tell me about animals\"],\n",
    "    #n_results=2\n",
    ")\n",
    "\n",
    "print(\"Results:\", results['documents'])\n",
    "print(\"Distances:\", results['distances'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c462ab5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for doc1 (first 5 numbers): [ 0.13040181 -0.01187013 -0.02811698  0.05123861 -0.05597446]\n",
      "Vector length: 384\n",
      "\n",
      "Distance to doc1: 0.9752495288848877\n",
      "Distance to doc2: 1.356661319732666\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "client = chromadb.PersistentClient(path=\"./data/test_db\")\n",
    "collection = client.get_or_create_collection(name=\"test\")\n",
    "\n",
    "collection.add(\n",
    "    documents=[\"The cat sat on the mat\", \"The dog played\"],\n",
    "    ids=[\"doc1\", \"doc2\"]\n",
    ")\n",
    "\n",
    "# Get the raw data\n",
    "result = collection.get(ids=[\"doc1\"], include=[\"embeddings\"])\n",
    "print(\"Vector for doc1 (first 5 numbers):\", result['embeddings'][0][:5])\n",
    "print(\"Vector length:\", len(result['embeddings'][0]))\n",
    "\n",
    "# Now query\n",
    "query_result = collection.query(\n",
    "    query_texts=[\"cat\"],\n",
    "    n_results=2,\n",
    "    include=[\"embeddings\", \"distances\"]\n",
    ")\n",
    "print(\"\\nDistance to doc1:\", query_result['distances'][0][0])\n",
    "print(\"Distance to doc2:\", query_result['distances'][0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32fbb5e",
   "metadata": {},
   "source": [
    "- https://claude.ai/share/c86070ea-4fa0-4c73-bcf2-f3f635f042f0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2f391a",
   "metadata": {},
   "source": [
    "## End"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e45a00",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chromatest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
